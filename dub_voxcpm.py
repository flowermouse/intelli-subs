import re
import os
import argparse
import subprocess
import numpy as np
import soundfile as sf
from voxcpm import VoxCPM
from pydub import AudioSegment

PROMPT_AUDIO_PATH = "refs/sf.wav"
PROMPT_AUDIO_TEXT = "é‚£äº›æœ‰å¤´æœ‰è„¸çš„ç„¦ä¿Šå±…æ°‘å®Œå…¨ä¸è®²é€»è¾‘ï¼ŒæŠŠå®¶é—¨å£å½“ä½œæ‹¼æ­»ä¸€æçš„é˜µåœ°ï¼Œä¸ä»–ä»¬é™ˆè…ä¹å‘³ï¼Œæ­»æ°”æ²‰æ²‰çš„ç”Ÿæ´»ç›¸å¯¹æŠ—ã€‚ä¸ºäº†å¾—åˆ°å…è´¹çš„æŠ«è¨ï¼Œä»–ä»¬å¯¹åˆ«äººæ’’è°ï¼ŒåŒæ—¶ä¹Ÿè‡ªæ¬ºæ¬ºäººï¼Œç¼–é€ æ‰“ç”µè¯è®¢å¤–å–çš„æ—¶é—´ã€‚"
SAMPLE_RATE = 44100


def parse_srt(file_path, merge_gap_ms=300):
    """è§£æ SRT æ–‡ä»¶ï¼Œè¿”å›å­—å¹•åˆ—è¡¨ [{'start_ms': int, 'end_ms': int, 'text': str}, ...]
    è‹¥ç›¸é‚»ä¸¤æ¡å­—å¹•çš„é—´éš” <= merge_gap_msï¼Œåˆ™åˆå¹¶ä¸ºä¸€æ¡ã€‚
    """
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()

    pattern = re.compile(
        r"(\d+)\s+([\d:,]+)\s+-->\s+([\d:,]+)\s+([\s\S]+?)(?=\n\n|\Z)",
        re.MULTILINE,
    )
    raw_subtitles = []

    for match in pattern.finditer(content):
        index = int(match.group(1))
        start = srt_time_to_ms(match.group(2))
        end = srt_time_to_ms(match.group(3))
        text = match.group(4).strip().replace("\n", " ")

        raw_subtitles.append(
            {"index": index, "start_ms": start, "end_ms": end, "text": text}
        )

    if not raw_subtitles:
        return []

    # åˆå¹¶é—´éš” <= merge_gap_ms çš„ç›¸é‚»å­—å¹•
    merged = []
    current = raw_subtitles[0].copy()

    for sub in raw_subtitles[1:]:
        gap = sub["start_ms"] - current["end_ms"]
        if gap <= merge_gap_ms:
            # åˆå¹¶ï¼šèµ·å§‹æ—¶é—´å–å½“å‰çš„ï¼Œç»“æŸæ—¶é—´å–åä¸€æ¡çš„ï¼Œæ–‡æœ¬æ‹¼æ¥
            current["end_ms"] = max(current["end_ms"], sub["end_ms"])
            current["text"] = (
                current["text"].rstrip() + " " + sub["text"].lstrip()
            )
        else:
            merged.append(current)
            current = sub.copy()

    merged.append(current)

    # é‡æ–°ç¼–å· index
    for i, sub in enumerate(merged, start=1):
        sub["index"] = i

    return merged


def srt_time_to_ms(time_str):
    """å°† SRT æ—¶é—´æ ¼å¼ (HH:MM:SS,mmm) è½¬æ¢ä¸ºæ¯«ç§’"""
    hours, minutes, seconds = time_str.split(":")
    seconds, milliseconds = seconds.split(",")
    total_ms = (
        int(hours) * 3600000
        + int(minutes) * 60000
        + int(seconds) * 1000
        + int(milliseconds)
    )
    return total_ms


def ffmpeg_time_stretch(wav: np.ndarray, speed: float) -> AudioSegment:
    """ä½¿ç”¨ ffmpeg atempo åšé«˜è´¨é‡å˜é€Ÿä¸å˜è°ƒ"""
    import tempfile

    # å†™å…¥ä¸´æ—¶ wav
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f_in, \
         tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f_out:
        sf.write(f_in.name, wav, SAMPLE_RATE)

        # atempo å˜é€Ÿï¼›>2 æˆ– <0.5 æ—¶å¯ä»¥å…ˆæˆªæ–­åœ¨è¿™ä¸ªèŒƒå›´
        speed = max(0.5, min(2.0, float(speed)))
        cmd = [
            "ffmpeg",
            "-y",
            "-loglevel", "error",
            "-i", f_in.name,
            "-filter:a", f"atempo={speed}",
            f_out.name,
        ]
        subprocess.run(cmd, check=True)

        seg = AudioSegment.from_wav(f_out.name)

    os.remove(f_in.name)
    os.remove(f_out.name)
    return seg


def generate_audio_for_text(text, model, duration):
    """ç”¨ VoxCPM ç”ŸæˆéŸ³é¢‘ï¼Œå¹¶ç”¨ ffmpeg atempo è°ƒæ•´åˆ° duration é•¿åº¦"""
    wav = model.generate(
        text=text,
        prompt_wav_path=PROMPT_AUDIO_PATH,
        prompt_text=PROMPT_AUDIO_TEXT,
        cfg_value=2.0,
        inference_timesteps=10,
        normalize=False,
        denoise=False,
        retry_badcase=True,
        retry_badcase_max_times=3,
        retry_badcase_ratio_threshold=6.0,
    )

    # VoxCPM ä¸€èˆ¬è¾“å‡º float [-1, 1]ï¼Œç¡®ä¿æ˜¯ float32
    wav = wav.astype(np.float32, copy=False)

    # åŸå§‹/ç›®æ ‡æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    orig_len_ms = len(wav) / SAMPLE_RATE * 1000.0
    target_len_ms = max(1, int(duration))

    # éœ€è¦çš„å˜é€Ÿå€æ•°ï¼š>1 åŠ é€Ÿï¼Œ<1 å‡é€Ÿ
    speed = orig_len_ms / target_len_ms

    # ç”¨ ffmpeg atempo åšé«˜è´¨é‡ time-stretch
    seg = ffmpeg_time_stretch(wav, speed)

    # å†ç²¾ç¡®è£å‰ª/è¡¥é™éŸ³åˆ°ç›®æ ‡é•¿åº¦ï¼Œé¿å…ç´¯è®¡è¯¯å·®
    if len(seg) < target_len_ms:
        seg += AudioSegment.silent(
            duration=target_len_ms - len(seg),
            frame_rate=SAMPLE_RATE,
        )
    else:
        seg = seg[:target_len_ms]

    return seg


def align_and_merge_audio(subtitles, model):
    merged = AudioSegment.silent(duration=0, frame_rate=SAMPLE_RATE)
    for i, sub in enumerate(subtitles):
        start_ms = sub["start_ms"]
        end_ms = sub["end_ms"]
        text = sub["text"]
        print(
            f"[{i+1}/{len(subtitles)}] ç”ŸæˆéŸ³é¢‘: {text[:30]}... ({start_ms}ms -> {end_ms}ms)"
        )
        subtitle_duration = end_ms - start_ms
        threshold = (
            subtitles[i + 1]["start_ms"] - start_ms
            if i + 1 < len(subtitles)
            else float("inf")
        )
        seg = generate_audio_for_text(text, model, subtitle_duration)
        if threshold == float("inf"):
            merged += seg
            break
        if len(seg) >= threshold:
            seg = seg[:threshold]
        else:
            silence_duration = threshold - len(seg)
            seg += AudioSegment.silent(
                duration=silence_duration, frame_rate=SAMPLE_RATE
            )
        merged += seg
    return merged


def main():
    parser = argparse.ArgumentParser(description="æ ¹æ® SRT æ–‡ä»¶ç”Ÿæˆé…éŸ³éŸ³é¢‘")
    parser.add_argument("--srt", required=True, help="è¾“å…¥ SRT å­—å¹•æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "--output_file", required=True, help="è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆwav æ ¼å¼ï¼‰"
    )
    args = parser.parse_args()

    model = VoxCPM.from_pretrained("openbmb/VoxCPM1.5")

    print(f"ğŸ“– è§£æå­—å¹•æ–‡ä»¶: {args.srt}")
    subtitles = parse_srt(args.srt)
    print(f"âœ… å…± {len(subtitles)} æ¡å­—å¹•\n")

    print("ğŸ™ï¸  å¼€å§‹ç”Ÿæˆå¹¶å¯¹é½éŸ³é¢‘...")
    merged_audio = align_and_merge_audio(subtitles, model)

    print(f"\nğŸ’¾ ä¿å­˜éŸ³é¢‘æ–‡ä»¶: {args.output_file}")
    merged_audio.export(args.output_file, format="wav")
    print("âœ… å®Œæˆï¼")


if __name__ == "__main__":
    main()
